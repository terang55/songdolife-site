"""
ë…¼í˜„ë™ ì •ë³´ í¬ë¡¤ëŸ¬ ìŠ¤ì¼€ì¤„ëŸ¬
ì •ê¸°ì ìœ¼ë¡œ í¬ë¡¤ë§ì„ ì‹¤í–‰í•˜ì—¬ ìµœì‹  ì •ë³´ë¥¼ ìˆ˜ì§‘
"""

import schedule
import time
import threading
from datetime import datetime
from main_crawler import NonhyeonCrawler
from loguru import logger
import config

class CrawlerScheduler:
    def __init__(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”"""
        self.running = False
        self.crawler = NonhyeonCrawler()
        self.setup_schedules()
        
    def setup_schedules(self):
        """í¬ë¡¤ë§ ìŠ¤ì¼€ì¤„ ì„¤ì •"""
        # ë§¤ì¼ ì˜¤ì „ 8ì‹œì— ì „ì²´ í¬ë¡¤ë§
        schedule.every().day.at("08:00").do(self.run_full_crawl)
        
        # ë§¤ì¼ ì˜¤í›„ 2ì‹œì— ë‰´ìŠ¤ë§Œ í¬ë¡¤ë§
        schedule.every().day.at("14:00").do(self.run_news_crawl)
        
        # ë§¤ì¼ ì˜¤í›„ 8ì‹œì— ì¹´íŽ˜ í¬ë¡¤ë§
        schedule.every().day.at("20:00").do(self.run_cafe_crawl)
        
        # ë§¤ 3ì‹œê°„ë§ˆë‹¤ í•« í‚¤ì›Œë“œ í¬ë¡¤ë§
        schedule.every(3).hours.do(self.run_hot_keywords_crawl)
        
        logger.info("í¬ë¡¤ë§ ìŠ¤ì¼€ì¤„ ì„¤ì • ì™„ë£Œ")
        logger.info("- ë§¤ì¼ 08:00: ì „ì²´ í¬ë¡¤ë§")
        logger.info("- ë§¤ì¼ 14:00: ë‰´ìŠ¤ í¬ë¡¤ë§")
        logger.info("- ë§¤ì¼ 20:00: ì¹´íŽ˜ í¬ë¡¤ë§")
        logger.info("- ë§¤ 3ì‹œê°„: í•« í‚¤ì›Œë“œ í¬ë¡¤ë§")

    def run_full_crawl(self):
        """ì „ì²´ í¬ë¡¤ë§ ì‹¤í–‰"""
        try:
            logger.info("ðŸ“‹ ìŠ¤ì¼€ì¤„ëœ ì „ì²´ í¬ë¡¤ë§ ì‹œìž‘")
            success = self.crawler.run_full_crawl()
            
            if success:
                logger.info("âœ… ìŠ¤ì¼€ì¤„ëœ ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ")
            else:
                logger.error("âŒ ìŠ¤ì¼€ì¤„ëœ ì „ì²´ í¬ë¡¤ë§ ì‹¤íŒ¨")
                
        except Exception as e:
            logger.error(f"ì „ì²´ í¬ë¡¤ë§ ì˜¤ë¥˜: {str(e)}")

    def run_news_crawl(self):
        """ë‰´ìŠ¤ë§Œ í¬ë¡¤ë§"""
        try:
            logger.info("ðŸ“° ìŠ¤ì¼€ì¤„ëœ ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹œìž‘")
            
            if not self.crawler.create_webdriver():
                logger.error("ì›¹ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨")
                return
            
            total_news = 0
            for keyword in config.SEARCH_KEYWORDS:
                news_data = self.crawler.crawl_naver_news(keyword)
                if news_data:
                    self.crawler.save_data(news_data, "news", keyword)
                    total_news += len(news_data)
                    
                time.sleep(config.DELAY_BETWEEN_REQUESTS)
            
            logger.info(f"âœ… ìŠ¤ì¼€ì¤„ëœ ë‰´ìŠ¤ í¬ë¡¤ë§ ì™„ë£Œ: {total_news}ê°œ ê¸°ì‚¬")
            
        except Exception as e:
            logger.error(f"ë‰´ìŠ¤ í¬ë¡¤ë§ ì˜¤ë¥˜: {str(e)}")
        finally:
            if self.crawler.driver:
                self.crawler.driver.quit()

    def run_cafe_crawl(self):
        """ì¹´íŽ˜ë§Œ í¬ë¡¤ë§"""
        try:
            logger.info("â˜• ìŠ¤ì¼€ì¤„ëœ ì¹´íŽ˜ í¬ë¡¤ë§ ì‹œìž‘")
            
            if not self.crawler.create_webdriver():
                logger.error("ì›¹ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨")
                return
            
            total_cafe = 0
            for keyword in config.SEARCH_KEYWORDS:
                cafe_data = self.crawler.crawl_naver_cafe_search(keyword)
                if cafe_data:
                    self.crawler.save_data(cafe_data, "cafe", keyword)
                    total_cafe += len(cafe_data)
                    
                time.sleep(config.DELAY_BETWEEN_REQUESTS)
            
            logger.info(f"âœ… ìŠ¤ì¼€ì¤„ëœ ì¹´íŽ˜ í¬ë¡¤ë§ ì™„ë£Œ: {total_cafe}ê°œ ê¸€")
            
        except Exception as e:
            logger.error(f"ì¹´íŽ˜ í¬ë¡¤ë§ ì˜¤ë¥˜: {str(e)}")
        finally:
            if self.crawler.driver:
                self.crawler.driver.quit()

    def run_hot_keywords_crawl(self):
        """í•« í‚¤ì›Œë“œ í¬ë¡¤ë§"""
        try:
            logger.info("ðŸ”¥ í•« í‚¤ì›Œë“œ í¬ë¡¤ë§ ì‹œìž‘")
            
            # ë…¼í˜„ë™ ê´€ë ¨ ì¸ê¸° í‚¤ì›Œë“œë“¤
            hot_keywords = [
                "ë…¼í˜„ë™ ë§›ì§‘",
                "ë…¼í˜„ë™ ì¹´íŽ˜",
                "ë…¼í˜„ë™ ìœ¡ì•„",
                "ë…¼í˜„ë™ ë¶€ë™ì‚°"
            ]
            
            if not self.crawler.create_webdriver():
                logger.error("ì›¹ë“œë¼ì´ë²„ ìƒì„± ì‹¤íŒ¨")
                return
            
            total_items = 0
            for keyword in hot_keywords:
                # ë‰´ìŠ¤ ìˆ˜ì§‘
                news_data = self.crawler.crawl_naver_news(keyword)
                if news_data:
                    self.crawler.save_data(news_data, "news", f"hot_{keyword}")
                    total_items += len(news_data)
                
                # ì¹´íŽ˜ ìˆ˜ì§‘
                cafe_data = self.crawler.crawl_naver_cafe_search(keyword)
                if cafe_data:
                    self.crawler.save_data(cafe_data, "cafe", f"hot_{keyword}")
                    total_items += len(cafe_data)
                    
                time.sleep(config.DELAY_BETWEEN_REQUESTS)
            
            logger.info(f"âœ… í•« í‚¤ì›Œë“œ í¬ë¡¤ë§ ì™„ë£Œ: {total_items}ê°œ í•­ëª©")
            
        except Exception as e:
            logger.error(f"í•« í‚¤ì›Œë“œ í¬ë¡¤ë§ ì˜¤ë¥˜: {str(e)}")
        finally:
            if self.crawler.driver:
                self.crawler.driver.quit()

    def start_scheduler(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œìž‘"""
        self.running = True
        logger.info("ðŸ• ë…¼í˜„ë™ í¬ë¡¤ëŸ¬ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œìž‘")
        
        while self.running:
            try:
                schedule.run_pending()
                time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ìŠ¤ì¼€ì¤„ í™•ì¸
                
            except KeyboardInterrupt:
                logger.info("ì‚¬ìš©ìžì— ì˜í•´ ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ë‹¨")
                break
            except Exception as e:
                logger.error(f"ìŠ¤ì¼€ì¤„ëŸ¬ ì˜¤ë¥˜: {str(e)}")
                time.sleep(60)

    def stop_scheduler(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€"""
        self.running = False
        logger.info("ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€ ìš”ì²­")

    def get_next_run_times(self):
        """ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ë“¤ ì¡°íšŒ"""
        jobs = schedule.get_jobs()
        next_runs = []
        
        for job in jobs:
            next_runs.append({
                "job": str(job.job_func.__name__),
                "next_run": job.next_run.strftime("%Y-%m-%d %H:%M:%S") if job.next_run else "ì—†ìŒ"
            })
        
        return next_runs

def run_scheduler_daemon():
    """ë°ëª¬ ëª¨ë“œë¡œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰"""
    scheduler = CrawlerScheduler()
    
    # ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ ì¶œë ¥
    print("ðŸ“… ì˜ˆì •ëœ í¬ë¡¤ë§ ì¼ì •:")
    for run_info in scheduler.get_next_run_times():
        print(f"   {run_info['job']}: {run_info['next_run']}")
    
    print("\nìŠ¤ì¼€ì¤„ëŸ¬ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤...")
    print("ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.\n")
    
    try:
        scheduler.start_scheduler()
    except KeyboardInterrupt:
        print("\nìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        scheduler.stop_scheduler()

def run_scheduler_interactive():
    """ì¸í„°ëž™í‹°ë¸Œ ëª¨ë“œë¡œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰"""
    scheduler = CrawlerScheduler()
    
    print("ðŸ• ë…¼í˜„ë™ í¬ë¡¤ëŸ¬ ìŠ¤ì¼€ì¤„ëŸ¬")
    print("=" * 50)
    
    while True:
        print("\nðŸ“‹ ìŠ¤ì¼€ì¤„ëŸ¬ ë©”ë‰´:")
        print("1. ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œìž‘")
        print("2. ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ í™•ì¸")
        print("3. ì¦‰ì‹œ ì „ì²´ í¬ë¡¤ë§ ì‹¤í–‰")
        print("4. ì¦‰ì‹œ ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤í–‰")
        print("5. ì¦‰ì‹œ ì¹´íŽ˜ í¬ë¡¤ë§ ì‹¤í–‰")
        print("6. ì¢…ë£Œ")
        
        choice = input("\nì„ íƒí•˜ì„¸ìš” (1-6): ").strip()
        
        if choice == "1":
            print("ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì‹œìž‘í•©ë‹ˆë‹¤...")
            thread = threading.Thread(target=scheduler.start_scheduler)
            thread.daemon = True
            thread.start()
            print("âœ… ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ ì¤‘ìž…ë‹ˆë‹¤.")
            
        elif choice == "2":
            print("\nðŸ“… ë‹¤ìŒ ì‹¤í–‰ ì˜ˆì •:")
            for run_info in scheduler.get_next_run_times():
                print(f"   {run_info['job']}: {run_info['next_run']}")
                
        elif choice == "3":
            scheduler.run_full_crawl()
            
        elif choice == "4":
            scheduler.run_news_crawl()
            
        elif choice == "5":
            scheduler.run_cafe_crawl()
            
        elif choice == "6":
            scheduler.stop_scheduler()
            print("ðŸ‘‹ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
            
        else:
            print("âŒ ìž˜ëª»ëœ ì„ íƒìž…ë‹ˆë‹¤.")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--daemon":
        run_scheduler_daemon()
    else:
        run_scheduler_interactive()

if __name__ == "__main__":
    main() 